<features> ::= <pooling> | <convolution> | <batch-norm>
<convolution> ::= layer:conv1d [num-filters,int,1,4,512] [filter-shape,int,1,2,75] [stride,int,1,1,20] <padding> <activation-function> <bias>
<pooling> ::= <pool-type> [kernel-size,int,1,2,75] [stride,int,1,2,75] <padding>
<pool-type> ::= layer:pool-avg1d | layer:pool-max1d
<padding> ::= padding:same | padding:valid
<batch-norm> ::= layer:batch-norm
<classification> ::= <fully-connected> | <dropout>
<fully-connected> ::= layer:fc <activation-function> [num-units,int,1,128,9128] <bias> 
<activation-function> ::= act:linear | act:relu | act:selu
<bias> ::= bias:True | bias:False
<dropout> ::= layer:dropout [rate,float,1,0,0.7]
<output> ::= layer:fc act:softmax num-units:256 bias:True
<learning> ::= learning:adam-std <early-stop> [batch_size,int,1,100,500] epochs:10000
<early-stop> ::= [early_stop,int,1,5,20]
